{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHat bot Memory\n",
    "1+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install langchain-groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "'''\n",
    "list of models we can use, there are more u can chech out - https://console.groq.com/docs/models\n",
    "distil-whisper-large-v3-en, gemma2-9b-it, llama-3.3-70b-versatile, llama-3.1-8b-instant, \n",
    "llama-guard-3-8b, llama3-70b-8192, llama3-8b-8192, mixtral-8x7b-32768, whisper-large-v3, whisper-large-v3-turbo\n",
    "'''\n",
    "model = ChatGroq(model = 'gemma2-9b-it')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! üëã \\n\\nHow can I help you today? üòä\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 11, 'total_tokens': 27, 'completion_time': 0.029090909, 'prompt_time': 0.001907246, 'queue_time': 0.016906781, 'total_time': 0.030998155}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-be31318b-ae6a-405e-95bc-b31637162ce4-0', usage_metadata={'input_tokens': 11, 'output_tokens': 16, 'total_tokens': 27})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke('Hello')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"That's wonderful to hear! It's great that you have confidence in yourself.\\n\\nRemember, everyone has their own unique strengths and qualities that make them special. Keep being the best version of yourself!\\n\\nIs there anything I can help you with today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 15, 'total_tokens': 71, 'completion_time': 0.101818182, 'prompt_time': 0.001951925, 'queue_time': 0.020643134, 'total_time': 0.103770107}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-15006b13-8b76-4de1-a0f6-65bab5d8d71d-0', usage_metadata={'input_tokens': 15, 'output_tokens': 56, 'total_tokens': 71})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([HumanMessage(content='I am a great human being')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Omkar Shirke, a person who believes they are a great human being! \\n\\nIs there anything else you'd like to tell me about yourself? I'm eager to learn more!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 47, 'total_tokens': 92, 'completion_time': 0.081818182, 'prompt_time': 0.002553857, 'queue_time': 0.018924232, 'total_time': 0.084372039}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-0b4a45d2-94ae-4e3c-9c4a-48a8d9413c21-0', usage_metadata={'input_tokens': 47, 'output_tokens': 45, 'total_tokens': 92})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "model.invoke([\n",
    "    HumanMessage(content='I am a great human being, Omkar Shirke'),\n",
    "    AIMessage(content='Thats wonderful to hear! Its great that you have confidence in yourself'),\n",
    "    HumanMessage(content='Who am i?')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# But see everytime we cannot write HumanMessage, AI message write So there comes below function\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "\n",
    "store = {} # session_id + session ki chat history store karne k liye use hoti hai\n",
    "\n",
    "# Abhi hum ek function banayege jisme ki hum store variable mai chat history store karenge \n",
    "# if already available nai ho add karenge \n",
    "\n",
    "def get_session_history(session_id:str)-> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = ChatMessageHistory()\n",
    "        \n",
    "    return store[session_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Abhi hum chain banayenge\n",
    "chain_chat_history = RunnableWithMessageHistory(model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yaha Humara user message and session id pass karenge in config parameter\n",
    "response = chain_chat_history.invoke(\n",
    "    [HumanMessage(content='I am Omkar Shirke and I am finding the purpose of life!!!!!!')],\n",
    "    config={'configurable':{'session_id':'user1'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"It's awesome that you're on this quest, Omkar!  Figuring out the purpose of life is a big adventure, and it's unique for everyone.  \\n\\nHere's the thing: there's no single right answer.  It's more about discovering what makes *you* feel fulfilled and gives your life meaning. \\n\\nTo help you on your way, think about these questions:\\n\\n* **What are you passionate about?** What activities make you lose track of time? What could you talk about for hours?\\n* **What are your values?** What's most important to you in life?  Honesty?  Creativity?  Helping others?\\n* **What are you good at?** What comes naturally to you?  What do people compliment you on?\\n\\nOnce you have a better understanding of yourself, you can start exploring different possibilities.\\n\\n* **Try new things!** You never know what might spark your interest.\\n* **Talk to people you admire.**  What drives them? What advice would they give?\\n* **Volunteer or help others.**  Making a difference in the world can be incredibly fulfilling.\\n\\nRemember, finding your purpose is a journey, not a destination.  Be patient with yourself, keep exploring, and enjoy the ride! \\n\\n\\nLet me know if you want to brainstorm some ideas together. I'm here to help!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 293, 'prompt_tokens': 465, 'total_tokens': 758, 'completion_time': 0.532727273, 'prompt_time': 0.020678666, 'queue_time': 0.023142211000000003, 'total_time': 0.553405939}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8f1aff6e-1d74-4a3c-bdcd-b49f2f827455-0', usage_metadata={'input_tokens': 465, 'output_tokens': 293, 'total_tokens': 758})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Omkar Shirke, as you told me earlier!  üòä  \\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 770, 'total_tokens': 801, 'completion_time': 0.056363636, 'prompt_time': 0.027301583, 'queue_time': 0.020336962999999996, 'total_time': 0.083665219}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c40d3323-1e3c-4e91-8bdd-daf81fafb2e4-0', usage_metadata={'input_tokens': 770, 'output_tokens': 31, 'total_tokens': 801})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_chat_history.invoke(\n",
    "    [HumanMessage(content='Whats my name??')],\n",
    "    config={'configurable':{'session_id':'user1'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='I am Omkar Shirke and I am finding the purpose of life!!!!!!', additional_kwargs={}, response_metadata={}), AIMessage(content=\"It's great that you're on this journey of self-discovery, Omkar! Finding the purpose of life is a deeply personal and unique quest for everyone. There's no one-size-fits-all answer, but here are some things that might help you along the way:\\n\\n**Reflect on What Matters to You:**\\n\\n* **Values:** What principles guide your actions and decisions? What do you believe in deeply?\\n* **Passions:** What activities make you lose track of time? What are you naturally drawn to?\\n* **Strengths:** What are you good at? What comes easily to you?\\n* **Interests:** What topics fascinate you? What do you enjoy learning about?\\n\\n**Explore Different Possibilities:**\\n\\n* **Try new things:** Step outside your comfort zone and experiment with different hobbies, activities, and experiences.\\n* **Connect with others:** Talk to people you admire, learn about their journeys, and seek their perspectives.\\n* **Travel and learn about different cultures:** Broaden your horizons and gain new insights into the world.\\n* **Read books and articles:** Explore different philosophies, beliefs, and perspectives on life's purpose.\\n\\n**Consider Your Impact:**\\n\\n* **How can you make a difference in the world?** This could involve helping others, contributing to your community, or advocating for a cause you believe in.\\n* **What kind of legacy do you want to leave behind?**\\n\\n**Remember:**\\n\\n* **Your purpose may evolve over time:** It's okay if your understanding of your purpose changes as you grow and learn.\\n* **There's no rush:** Take your time and be patient with yourself.\\n* **Focus on the journey, not just the destination:** The process of searching for your purpose can be just as rewarding as finding it.\\n\\n**I'm here to support you on this journey, Omkar. If you want to explore any of these ideas further, or if you have any other questions, feel free to ask.**\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 418, 'prompt_tokens': 24, 'total_tokens': 442, 'completion_time': 0.76, 'prompt_time': 0.002121116, 'queue_time': 0.016602412, 'total_time': 0.762121116}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b9758cfa-2fa2-4f21-8613-408eecff775f-0', usage_metadata={'input_tokens': 24, 'output_tokens': 418, 'total_tokens': 442}), HumanMessage(content='I am Omkar Shirke and I am finding the purpose of life!!!!!!', additional_kwargs={}, response_metadata={}), AIMessage(content=\"It's awesome that you're on this quest, Omkar!  Figuring out the purpose of life is a big adventure, and it's unique for everyone.  \\n\\nHere's the thing: there's no single right answer.  It's more about discovering what makes *you* feel fulfilled and gives your life meaning. \\n\\nTo help you on your way, think about these questions:\\n\\n* **What are you passionate about?** What activities make you lose track of time? What could you talk about for hours?\\n* **What are your values?** What's most important to you in life?  Honesty?  Creativity?  Helping others?\\n* **What are you good at?** What comes naturally to you?  What do people compliment you on?\\n\\nOnce you have a better understanding of yourself, you can start exploring different possibilities.\\n\\n* **Try new things!** You never know what might spark your interest.\\n* **Talk to people you admire.**  What drives them? What advice would they give?\\n* **Volunteer or help others.**  Making a difference in the world can be incredibly fulfilling.\\n\\nRemember, finding your purpose is a journey, not a destination.  Be patient with yourself, keep exploring, and enjoy the ride! \\n\\n\\nLet me know if you want to brainstorm some ideas together. I'm here to help!\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 293, 'prompt_tokens': 465, 'total_tokens': 758, 'completion_time': 0.532727273, 'prompt_time': 0.020678666, 'queue_time': 0.023142211000000003, 'total_time': 0.553405939}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8f1aff6e-1d74-4a3c-bdcd-b49f2f827455-0', usage_metadata={'input_tokens': 465, 'output_tokens': 293, 'total_tokens': 758}), HumanMessage(content='Whats my name??', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Omkar Shirke, as you told me earlier!  üòä  \\n\\nIs there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 31, 'prompt_tokens': 770, 'total_tokens': 801, 'completion_time': 0.056363636, 'prompt_time': 0.027301583, 'queue_time': 0.020336962999999996, 'total_time': 0.083665219}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c40d3323-1e3c-4e91-8bdd-daf81fafb2e4-0', usage_metadata={'input_tokens': 770, 'output_tokens': 31, 'total_tokens': 801})])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_session_history('user1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I have no memory of past conversations and do not know your name.\\n\\nIf you'd like to tell me your name, I'm happy to know! üòä\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 41, 'prompt_tokens': 13, 'total_tokens': 54, 'completion_time': 0.074545455, 'prompt_time': 0.001910296, 'queue_time': 0.019237953000000002, 'total_time': 0.076455751}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-3d6de40d-18ff-410a-af38-0a9f14a6180b-0', usage_metadata={'input_tokens': 13, 'output_tokens': 41, 'total_tokens': 54})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_chat_history.invoke(\n",
    "    [HumanMessage(content='Whats my name??')],\n",
    "    config={'configurable':{'session_id':'user2'}}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose you want your answer in a different language\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system','You are a great and fantastic stock researcher and financial analyst who gives stock recommendations in any {language}'),\n",
    "        MessagesPlaceholder(variable_name='messages')\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='‡§Æ‡•à‡§Ç ‡§è‡§ï ‡§¨‡•ú‡§æ ‡§î‡§∞ ‡§∂‡§æ‡§®‡§¶‡§æ‡§∞ ‡§∏‡•ç‡§ü‡•â‡§ï ‡§∞‡§ø‡§∏‡§∞‡•ç‡§ö‡§∞ ‡§î‡§∞ ‡§µ‡§ø‡§§‡•ç‡§§‡•Ä‡§Ø ‡§µ‡§ø‡§∂‡•ç‡§≤‡•á‡§∑‡§ï ‡§π‡•Ç‡§Å ‡§ú‡•ã ‡§π‡§ø‡§Ç‡§¶‡•Ä ‡§Æ‡•á‡§Ç ‡§∏‡•ç‡§ü‡•â‡§ï ‡§∏‡§ø‡§´‡§æ‡§∞‡§ø‡§∂‡•á‡§Ç ‡§¶‡•á‡§§‡§æ ‡§π‡•Ç‡§Å‡•§ \\n\\n‡§≤‡•á‡§ï‡§ø‡§®, ‡§Æ‡•Å‡§ù‡•á ‡§Æ‡§æ‡§´‡§º ‡§ï‡§∞‡§®‡§æ, ‡§Æ‡•à‡§Ç ‡§ï‡•ã‡§à ‡§®‡§ø‡§µ‡•á‡§∂ ‡§∏‡§≤‡§æ‡§π ‡§®‡§π‡•Ä‡§Ç ‡§¶‡•á ‡§∏‡§ï‡§§‡§æ‡•§ \\n\\n‡§®‡§ø‡§µ‡•á‡§∂ ‡§ï‡§∞‡§®‡§æ ‡§¨‡§π‡•Å‡§§ ‡§π‡•Ä ‡§µ‡•ç‡§Ø‡§ï‡•ç‡§§‡§ø‡§ó‡§§ ‡§π‡•ã‡§§‡§æ ‡§π‡•à ‡§î‡§∞ ‡§Ø‡§π ‡§∏‡§ø‡§∞‡•ç‡•û ‡§Ü‡§™‡§ï‡•á ‡§´‡§æ‡§á‡§®‡•á‡§Ç‡§∏‡§ø‡§Ø‡§≤ ‡§∏‡•ç‡§•‡§ø‡§§‡§ø, ‡§ú‡•ã‡§ñ‡§ø‡§Æ ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ ‡§î‡§∞ ‡§®‡§ø‡§µ‡•á‡§∂ ‡§≤‡§ï‡•ç‡§∑‡•ç‡§Ø‡•ã‡§Ç ‡§™‡§∞ ‡§®‡§ø‡§∞‡•ç‡§≠‡§∞ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§ \\n\\n‡§è‡§ï ‡§Ø‡•ã‡§ó‡•ç‡§Ø ‡§µ‡§ø‡§§‡•ç‡§§‡•Ä‡§Ø ‡§∏‡§≤‡§æ‡§π‡§ï‡§æ‡§∞ ‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§®‡§æ ‡§¨‡•á‡§π‡§§‡§∞ ‡§π‡•ã‡§ó‡§æ ‡§ú‡•ã ‡§Ü‡§™‡§ï‡•á ‡§≤‡§ø‡§è ‡§∏‡§¨‡§∏‡•á ‡§â‡§™‡§Ø‡•Å‡§ï‡•ç‡§§ ‡§®‡§ø‡§µ‡•á‡§∂ ‡§∞‡§£‡§®‡•Ä‡§§‡§ø ‡§ï‡§æ ‡§∏‡•Å‡§ù‡§æ‡§µ ‡§¶‡•á ‡§∏‡§ï‡•á‡•§ \\n\\n‡§Ü‡§™ ‡§ï‡•Å‡§õ ‡§Æ‡§π‡§§‡•ç‡§µ‡§™‡•Ç‡§∞‡•ç‡§£ ‡§¨‡§æ‡§§‡•ã‡§Ç ‡§™‡§∞ ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç:\\n\\n* **‡§Ö‡§™‡§®‡•á ‡§´‡§æ‡§á‡§®‡•á‡§Ç‡§∏‡§ø‡§Ø‡§≤ ‡§≤‡§ï‡•ç‡§∑‡•ç‡§Ø:** ‡§Ü‡§™ ‡§®‡§ø‡§µ‡•á‡§∂ ‡§∏‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§π‡§æ‡§∏‡§ø‡§≤ ‡§ï‡§∞‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç? \\n* **‡§ú‡•ã‡§ñ‡§ø‡§Æ ‡§ï‡•ç‡§∑‡§Æ‡§§‡§æ:** ‡§Ü‡§™ ‡§ï‡§ø‡§§‡§®‡§æ ‡§ú‡•ã‡§ñ‡§ø‡§Æ ‡§â‡§†‡§æ‡§®‡•á ‡§ï‡•ã ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•à‡§Ç? \\n* **‡§®‡§ø‡§µ‡•á‡§∂ ‡§Ö‡§µ‡§ß‡§ø:** ‡§Ü‡§™ ‡§Ö‡§™‡§®‡•á ‡§®‡§ø‡§µ‡•á‡§∂ ‡§ï‡•ã ‡§ï‡§ø‡§§‡§®‡•á ‡§∏‡§Æ‡§Ø ‡§ï‡•á ‡§≤‡§ø‡§è ‡§∞‡§ñ‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á? \\n\\n‡§á‡§® ‡§¨‡§æ‡§§‡•ã‡§Ç ‡§™‡§∞ ‡§µ‡§ø‡§ö‡§æ‡§∞ ‡§ï‡§∞‡§ï‡•á ‡§î‡§∞ ‡§è‡§ï ‡§µ‡§ø‡§§‡•ç‡§§‡•Ä‡§Ø ‡§∏‡§≤‡§æ‡§π‡§ï‡§æ‡§∞ ‡§∏‡•á ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§ï‡•á, ‡§Ü‡§™ ‡§è‡§ï ‡§∏‡•Ç‡§ö‡§ø‡§§ ‡§®‡§ø‡§µ‡•á‡§∂ ‡§®‡§ø‡§∞‡•ç‡§£‡§Ø ‡§≤‡•á ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç‡•§\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 275, 'prompt_tokens': 32, 'total_tokens': 307, 'completion_time': 0.5, 'prompt_time': 0.002344054, 'queue_time': 0.015473935999999999, 'total_time': 0.502344054}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-9c7ba2f7-5fa6-4b32-88a3-5982b5367a6f-0', usage_metadata={'input_tokens': 32, 'output_tokens': 275, 'total_tokens': 307})"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"What should I buy man\")], 'language' : 'Hindi'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\DATA SCIENCE\\Building Agentic AI And Generative AI Application With Cloud (AWS And GCP)\\AgenticAI-Practical\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What happens if our chat history becomes very very big, in that case we have to trim our chat history play with max_tokens\n",
    "\n",
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=60,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you have to play with max_tokens \n",
    "trimmer2 = trim_messages(max_tokens = 20,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\")\n",
    "trimmer2.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You said you like vanilla ice cream!  üç¶ üòä \\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from operator import itemgetter\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    "    \n",
    ")\n",
    "response=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"What ice cream do i like\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
